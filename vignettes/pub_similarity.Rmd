---
title: "Computing the similarity of papers to an author's core set"
output: rmarkdown::html_vignette
description: >
  TODO
vignette: >
  %\VignetteIndexEntry{Paper similarity}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Goal of this exercise: Detect publications that are assigned to an author by OpenAlex, but actually do not belong to that person (i.e., a false-positive).

We build a matrix of concept scores, where rows are publications and columns are all concepts that appeared at least once in a publication. Concepts that were not assigned to a specific publication receive the score 0.



```{r}
library(dplyr)
library(tidyr)
library(openalexR)
library(lsa)

#author.id <- "https://openalex.org/A5083504666"  # Mitja
author.id <- "https://openalex.org/A5022479713" # Felix
#author.id <- "https://openalex.org/A5027778611"  # Julia Rohrer
author.id <- "https://openalex.org/A5091563836"   # Markus Steiner

# which concept levels should be included in the analysis?
included_levels <- 0:1

works <- oa_fetch(
  entity = "works",
  author.id = author.id,
  is_paratext = FALSE,
  is_retracted = FALSE,
  abstract=FALSE,
  verbose = FALSE
)

# filter out works that should not count for the h-index, and for the computation of academic age (i.e., works without doi and which are not published in an outlet).
# This is mostly irrelevant for the h-index, but important for the automatic retrieval of academic age.
works <- works %>% filter(!is.na(doi), !is.na(so))

# manually flag works that do not belong to Mitja Back
works$valid <- TRUE
works$valid[works$id %in% c("https://openalex.org/W3006987680", "https://openalex.org/W1966661272", "https://openalex.org/W3144672300", "https://openalex.org/W3106992603", "https://openalex.org/W3148118513", "https://openalex.org/W606769239", "https://openalex.org/W2548863919", "https://openalex.org/W4226327396", "https://openalex.org/W3144466282")] <- FALSE

con <- works$concepts

# add publication id and doi to concepts
for (i in 1:length(con)) {
  con[[i]]$pub_id <- works[i, ]$id
  con[[i]]$doi <- works[i, ]$doi
}
con.long <- data.table::rbindlist(con)

# reduce to required levels
con.long <- con.long %>% filter(level %in% included_levels)

con.wide <- pivot_wider(con.long, id_cols=c("pub_id", "doi"), names_from="display_name", values_from="score", values_fill=0)

# remove zero-variance columns
col_var <- apply(con.wide[, -c(1, 2)], 2, var)
con.wide <- con.wide[, !colnames(con.wide) %in% names(which(col_var == 0))]

con.mat <- con.wide[, -c(1, 2)] # remove publication id and doi column

works$ID <- 1:nrow(works)
works_reduced <- works[works$doi %in% con.wide$doi, ]
# verify that both data frames are in the same order, for later merging
all.equal(works_reduced$doi, con.wide$doi)

PCA <- princomp(cor(t(con.mat)))
plot(PCA$scores[, 1], PCA$scores[, 2])
```


The matrix is very sparse: `r (sum(con.wide==0)/sum(!is.na(con.wide))*100) |> round(1)`% of concept scores are exactly zero.
Given this sparsity, cosine similarity seems to be a good measure.

```{r}
# this is the core concept vector of an author
mean_concept_vector <- colMeans(con.mat)

sort(round(mean_concept_vector, 3), decreasing = TRUE)[1:20]

# add the core concept vector in row 1 as the reference
con.mat.addMean <- rbind(mean_concept_vector, con.mat)

# compute cosine similarity
sim <- lsa::cosine(t(as.matrix(con.mat.addMean)))

# extract distance to the core concept vector
sim_df <- data.frame(doi=con.wide$doi, core_sim=sim[1, -1])
works <- left_join(works, sim_df, by="doi")
works_reduced <- left_join(works_reduced, sim_df, by="doi")

works %>% arrange(-core_sim) %>% select(core_sim, valid, display_name, so, publication_year) %>% head(10)
works %>% arrange(-core_sim) %>% select(core_sim, valid, display_name, so, publication_year) %>% tail(20)

# publication with NA in the core_sim are mostly irrelevant publications
works %>% filter(is.na(core_sim)) %>% select(core_sim, valid, display_name, so, publication_year)

hist(works$core_sim)
```

This works already quite well, but assumes that publications have a single core set. But authors might have multiple clusters of activity, and the mean core concept vector might fall in between two clusters. Then every single publication will have a substantial distance to this rather meaningless average concept core.
Hence, a better approach might be to do k-means clustering and computing the probability of each publicationto fall into one of the clusters. This way, "lonely wolves" (which probably are publications erroneously attributed to that person) can be better identified.

```{r}
library(factoextra)
library(cluster)
library(fclust)

set.seed(0xBEEF)

# To account for the possibility that a data point doesn't fit well into any of the predefined clusters, an additional "cluster" or category can be introduced, which represents the absence of membership in any of the clusters. This is implemented in the `noise` parameter.
res.SIL <- data.frame()
for (k in 1:6) {
  print(paste0(k, "/", 10))
  fc <- Fclust(con.mat, k=k, noise=TRUE)
  res.SIL <- rbind(res.SIL, data.frame(
    k=k,
    t(unlist(Fclust.index(fc)))
  ))
}

res.SIL

fc <- Fclust(con.mat, k=2, noise=TRUE)

# U contains the membership probabilities
works_reduced$lonely_wolf_index <- 1-rowSums(fc$U)

LW <- works_reduced %>% arrange(-lonely_wolf_index) %>% select(lonely_wolf_index, display_name, so, publication_year, id)
head(LW)

library(ggplot2)
library(ggrepel)
ggplot(works_reduced, aes(x=lonely_wolf_index, y=core_sim, color=valid)) + geom_point() + geom_text_repel(aes(label=ID))

```

## Third attempt: Use the ORCID record

In my experience, ORCID record fewer publications than OpenAlex, but these are mostly correct. Hence, ORCID has mostly true positives but quite some false negatives, while OpenAlex has more true positive at the cost of more false positives. Can we combine the strengths of both?

Here, I try to use the ORCID publication record as a reference set to find false positive in the OpenAlex record:

```{r}

library(rorcid)
library(openalexR)
library(janitor)
library(dplyr)

au <- oa_fetch(entity="author", id=author.id)

au$orcid

library(httr)
# orcid_request <- POST(url  = "https://orcid.org/oauth/token",
#           config = add_headers(`Accept` = "application/json",
#                                `Content-Type` = "application/x-www-form-urlencoded"),
#           body = list(grant_type = "client_credentials",
#                       scope = "/read-public",
#                       client_id = "APP-R40M14OCJVHRX2T0",
#                       client_secret = "2ae4c4bc-0f1f-4efe-aecf-27681b9516cf"),
#           encode = "form")
# 
# orcid_response <- content(orcid_request)
# print(orcid_response$access_token)

orcid_works <- rorcid::works(substr(au$orcid, 19, 38)) %>%
  as_tibble() %>%
  janitor::clean_names() %>%
  dplyr::mutate(created_date_value = anytime::anydate(created_date_value/1000))

orcid_works_cleaned <- orcid_works %>% filter(!is.na(publication_date_year_value))

  
  orcid_works_cleaned$dois <- sapply(orcid_works_cleaned$external_ids_external_id, function(x) {
    if (length(x) == 0) {
      return(NA)
    } else {
      x2 <- x[x[, "external-id-type"] == "doi", ]
      if (nrow(x2) > 0) {
        return(x2[1, "external-id-normalized.value"])
      } else {
        return(NA)
      }
    }
    })
  
  orcid_works_cleaned$dois <- paste0("https://doi.org/", orcid_works_cleaned$dois)
  

works$in_ORCID <- works$doi %in%  orcid_works_cleaned$dois
works_reduced$in_ORCID <- works_reduced$doi %in%  orcid_works_cleaned$dois
con.wide$in_ORCID <- con.wide$doi %in%  orcid_works_cleaned$dois 
  
  
# add the ORCID mean concept vector in row 1 as the reference
mean_ORCID_vector <- colMeans(con.mat[con.wide$in_ORCID, ])
con.mat.addMean2 <- rbind(mean_ORCID_vector, con.mat)

# compute cosine similarity
sim2 <- lsa::cosine(t(as.matrix(con.mat.addMean2)))

# extract distance to the core concept vector
sim_df2 <- data.frame(doi=con.wide$doi, ORCID_sim=sim2[1, -1])
works <- left_join(works, sim_df2, by="doi")
works_reduced <- left_join(works_reduced, sim_df2, by="doi")

plot(works_reduced$core_sim, works_reduced$ORCID_sim)
cor(works_reduced$core_sim, works_reduced$ORCID_sim)

works_reduced %>% arrange(-core_sim) %>% select(core_sim, valid, display_name, so, publication_year) %>% tail(20)
works_reduced %>% arrange(-ORCID_sim) %>% select(ORCID_sim, valid, display_name, so, publication_year) %>% tail(20)

ggplot(works_reduced, aes(x=core_sim, y=ORCID_sim, color=valid)) + geom_point() + geom_text_repel(aes(label=ID))
ggplot(works_reduced %>% filter(ORCID_sim < .10), aes(x=core_sim, y=ORCID_sim, color=valid)) + geom_point() + geom_text_repel(aes(label=ID))

ggplot(works_reduced %>% filter(ORCID_sim < .10), aes(x=lonely_wolf_index, y=ORCID_sim, color=valid, shape=in_ORCID)) + geom_point() + geom_text_repel(aes(label=ID))

```

Which publications are added by OpenAlex, and are they valid?

Without selection by ORCID similarity:
```{r}
table("in ORCID"=works_reduced$in_ORCID, "Valid"=works_reduced$valid)
```


With selection by ORCID similarity (cutoff = .05):
```{r}
table("in ORCID"=works_reduced$in_ORCID, "Valid"=works$valid, "outlier"=works_reduced$ORCID_sim <=.05 & !works_reduced$in_ORCID)
```

Hence, the candidates for invalidly assigned publications are:

```{r}
works %>% filter(ORCID_sim <=.05 & !in_ORCID) %>% select(display_name, so, publication_year)
works %>% filter(is.na(core_sim)) %>% select(display_name, so, publication_year)
```

